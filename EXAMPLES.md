# üìö Exemples d'utilisation

Ce guide pr√©sente diff√©rents cas d'usage du scraper multi-pharmacies.

---

## üéØ Cas d'usage basiques

### 1. Scraper un seul produit

```bash
python3 main.py
# Choisir option 1
# Entrer l'EAN : 3337875762861
```

**R√©sultat :**
- Recherche sur les 3 sites
- Extraction compl√®te des donn√©es
- Fichier `product_3337875762861.json` cr√©√©

---

### 2. Scraper plusieurs produits

```bash
python3 main.py
# Choisir option 2
# Entrer : 3337875762861, 3282770114139, 3665606001874
```

**R√©sultat :**
- 3 fichiers JSON cr√©√©s
- Rapport dans la console pour chaque produit

---

### 3. Scraper depuis un fichier

**Cr√©er `eans.txt` :**

```
3337875762861
3282770114139
3665606001874
```

**Lancer :**

```bash
python3 main.py
# Choisir option 3
```

**R√©sultat :**
- Traitement s√©quentiel de tous les EAN
- Un fichier JSON par produit

---

## üîß Utilisation avanc√©e

### 4. Utilisation programmatique

**Cr√©er `my_script.py` :**

```python
#!/usr/bin/env python3
from main import MasterScraper

# Cr√©er le scraper
scraper = MasterScraper()

# Liste d'EAN √† traiter
eans = [
    "3337875762861",
    "3282770114139",
    "3665606001874"
]

# Traiter tous les EAN
for ean in eans:
    print(f"\n{'='*50}")
    print(f"Traitement de {ean}")
    print(f"{'='*50}")
    
    # Recherche
    results = scraper.search_all_sites(ean)
    
    # Extraction
    products = scraper.extract_products(ean, results)
    
    # Affichage
    scraper.display_results(products, ean)
```

---

### 5. Scraper uniquement un site sp√©cifique

**Cr√©er `scraper_single_site.py` :**

```python
#!/usr/bin/env python3
from searchers import CocooncenterSearcher
from scrapers import CocooncenterScraper

ean = "3337875762861"

# Recherche
searcher = CocooncenterSearcher()
found, url = searcher.search(ean)

if found:
    print(f"‚úÖ Produit trouv√© : {url}")
    
    # Extraction
    scraper = CocooncenterScraper()
    product = scraper.extract(url, ean)
    
    print(f"\nTitre : {product['titre']}")
    print(f"Prix : {product['prix']}")
    print(f"Note : {product.get('note', 'N/A')}")
else:
    print("‚ùå Produit non trouv√©")
```

---

### 6. Export personnalis√© (CSV)

**Cr√©er `export_csv.py` :**

```python
#!/usr/bin/env python3
import csv
from main import MasterScraper

def export_to_csv(ean):
    """Exporte les r√©sultats en CSV"""
    scraper = MasterScraper()
    
    # Recherche et extraction
    results = scraper.search_all_sites(ean)
    products = scraper.extract_products(ean, results)
    
    # Export CSV
    with open(f'product_{ean}.csv', 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        
        # En-t√™te
        writer.writerow(['Site', 'Titre', 'Prix', 'Note', 'Nb Avis', 'URL'])
        
        # Donn√©es
        for site, product in products.items():
            writer.writerow([
                product.get('site', ''),
                product.get('titre', ''),
                product.get('prix', ''),
                product.get('note', ''),
                product.get('nb_avis', ''),
                product.get('url', '')
            ])
    
    print(f"‚úÖ Export CSV : product_{ean}.csv")

# Utilisation
export_to_csv("3337875762861")
```

---

### 7. Comparateur de prix

**Cr√©er `price_comparator.py` :**

```python
#!/usr/bin/env python3
from main import MasterScraper
import re

def compare_prices(ean):
    """Compare les prix d'un produit sur tous les sites"""
    scraper = MasterScraper()
    
    results = scraper.search_all_sites(ean)
    products = scraper.extract_products(ean, results)
    
    if not products:
        print("‚ùå Produit non trouv√©")
        return
    
    print(f"\n{'='*60}")
    print(f"COMPARATEUR DE PRIX - EAN: {ean}")
    print(f"{'='*60}\n")
    
    # Extraire les prix
    prices = {}
    for site, product in products.items():
        prix_str = product.get('prix', '')
        match = re.search(r'([0-9,]+)', prix_str)
        if match:
            prix_float = float(match.group(1).replace(',', '.'))
            prices[site] = {
                'prix': prix_float,
                'titre': product.get('titre', ''),
                'url': product.get('url', '')
            }
    
    sorted_prices = sorted(prices.items(), key=lambda x: x[1]['prix'])
    
    for i, (site, info) in enumerate(sorted_prices, 1):
        medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else "  "
        print(f"{medal} {site.upper():<20} {info['prix']:.2f}‚Ç¨")
    
    if sorted_prices:
        best = sorted_prices[0]
        print(f"\nüí∞ MEILLEUR PRIX : {best[1]['prix']:.2f}‚Ç¨ sur {best[0].upper()}")
        print(f"üîó {best[1]['url']}")

compare_prices("3337875762861")
```

---

### 8. Surveillance des avis

**Cr√©er `monitor_reviews.py` :**

```python
#!/usr/bin/env python3
from main import MasterScraper

def monitor_reviews(ean):
    """Surveille les nouveaux avis clients"""
    scraper = MasterScraper()
    
    results = scraper.search_all_sites(ean)
    products = scraper.extract_products(ean, results)
    
    print(f"\n{'='*60}")
    print(f"SURVEILLANCE DES AVIS - EAN: {ean}")
    print(f"{'='*60}\n")
    
    for site, product in products.items():
        print(f"\nüè™ {product['site']}")
        print(f"{'‚îÄ'*60}")
        
        avis_clients = product.get('avis_clients', [])
        
        if not avis_clients:
            print("   Aucun avis disponible")
            continue
        
        print(f"   üìä Total avis : {product.get('nb_avis', 'N/A')}")
        print(f"   ‚≠ê Note moyenne : {product.get('note', 'N/A')}")
        print(f"\n   üìù Derniers avis :")
        
        for i, avis in enumerate(avis_clients[:3], 1):
            print(f"\n   Avis #{i}")
            print(f"   üë§ {avis.get('auteur', 'Anonyme')}")
            if 'date' in avis:
                print(f"   üìÖ {avis['date']}")
            print(f"   ‚≠ê {avis.get('note', 'N/A')}")
            texte = avis.get('avis', '')
            short = texte[:100] + "..." if len(texte) > 100 else texte
            print(f"   üí¨ {short}")

monitor_reviews("3337875762861")
```

---

### 9. Batch processing avec logging

**Cr√©er `batch_scraper.py` :**

```python
#!/usr/bin/env python3
import logging
from datetime import datetime
from main import MasterScraper

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'scraping_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)

def batch_scrape(eans_file):
    """Scrape un lot d'EAN avec logging"""
    scraper = MasterScraper()
    
    with open(eans_file, 'r', encoding='utf-8') as f:
        eans = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    logging.info("D√©but du batch - %d produits √† traiter", len(eans))
    
    stats = {
        'total': len(eans),
        'success': 0,
        'errors': 0,
        'not_found': 0
    }
    
    for idx, ean in enumerate(eans, 1):
        logging.info("[%d/%d] Traitement EAN: %s", idx, len(eans), ean)
        try:
            results = scraper.search_all_sites(ean)
            found_count = sum(1 for r in results.values() if r.found)
            
            if found_count == 0:
                logging.warning("EAN %s non trouv√© sur aucun site", ean)
                stats['not_found'] += 1
                continue
            
            products = scraper.extract_products(ean, results)
            
            if products:
                logging.info("‚úÖ EAN %s trait√© - %d site(s)", ean, len(products))
                stats['success'] += 1
            else:
                logging.error("‚ùå √âchec extraction EAN %s", ean)
                stats['errors'] += 1
        except Exception as exc:  # noqa: BLE001
            logging.exception("‚ùå Erreur EAN %s: %s", ean, exc)
            stats['errors'] += 1
    
    logging.info("="*60)
    logging.info("RAPPORT FINAL")
    logging.info("="*60)
    logging.info("Total : %d", stats['total'])
    logging.info("Succ√®s : %d", stats['success'])
    logging.info("Erreurs : %d", stats['errors'])
    logging.info("Non trouv√©s : %d", stats['not_found'])
    if stats['total']:
        logging.info("Taux de succ√®s : %.1f%%", stats['success']/stats['total']*100)

batch_scrape('eans.txt')
```

---

## üõ†Ô∏è Debugging et d√©pannage

### 10. Mode debug d√©taill√©

**Cr√©er `debug_scraper.py` :**

```python
#!/usr/bin/env python3
import logging
from scrapers import CocooncenterScraper

logging.basicConfig(level=logging.DEBUG)

ean = "3337875762861"
url = "https://www.cocooncenter.com/..."

scraper = CocooncenterScraper()

try:
    product = scraper.extract(url, ean)
    print("\n‚úÖ Extraction r√©ussie")
    print(f"Titre: {product.get('titre')}")
    print(f"Prix: {product.get('prix')}")
except Exception as exc:  # noqa: BLE001
    print(f"\n‚ùå Erreur: {exc}")
    import traceback
    traceback.print_exc()
```

---

## üìä Analyse des donn√©es

### 11. Statistiques globales

**Cr√©er `stats.py` :**

```python
#!/usr/bin/env python3
import glob
import json
import re
from collections import defaultdict

def analyze_results():
    """Analyse tous les fichiers JSON de r√©sultats"""
    files = glob.glob('product_*.json')
    
    if not files:
        print("‚ùå Aucun fichier de r√©sultats trouv√©")
        return
    
    stats = {
        'total_products': len(files),
        'by_site': defaultdict(int),
        'avg_price': [],
        'avg_rating': []
    }
    
    for file in files:
        with open(file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for site, product in data.items():
            stats['by_site'][site] += 1
            
            prix_str = product.get('prix', '')
            if prix_str:
                match = re.search(r'([0-9,]+)', prix_str)
                if match:
                    stats['avg_price'].append(float(match.group(1).replace(',', '.')))
            
            note_str = product.get('note', '')
            if note_str:
                match = re.search(r'([0-9.]+)', note_str)
                if match:
                    stats['avg_rating'].append(float(match.group(1)))
    
    print(f"\n{'='*60}")
    print("STATISTIQUES GLOBALES")
    print(f"{'='*60}\n")
    print(f"üì¶ Produits analys√©s : {stats['total_products']}")
    print("\nüè™ Par site :")
    for site, count in stats['by_site'].items():
        print(f"   - {site}: {count} produits")
    
    if stats['avg_price']:
        avg_price = sum(stats['avg_price']) / len(stats['avg_price'])
        print(f"\nüí∞ Prix moyen : {avg_price:.2f}‚Ç¨")
    
    if stats['avg_rating']:
        avg_rating = sum(stats['avg_rating']) / len(stats['avg_rating'])
        print(f"‚≠ê Note moyenne : {avg_rating:.2f}/5")

analyze_results()
```

---

Ces exemples couvrent les cas d'usage les plus courants. N'h√©sitez pas √† les adapter selon vos besoins !
